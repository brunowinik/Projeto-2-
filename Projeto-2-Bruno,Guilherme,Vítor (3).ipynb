{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dando imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos arquivos em Excel\n",
    "TweetsStarbucks = pd.read_excel('Tweets_Starbucks.xlsx')\n",
    "\n",
    "#Pegando somente o tweet:\n",
    "TweetsStarbucksTreinamento = TweetsStarbucks.drop('Classificação', axis=1)\n",
    "\n",
    "#Função para separar os EMOJIS:\n",
    "Lista_EMOJI = []\n",
    "for e in TweetsStarbucksTreinamento[\"Treinamento\"]:\n",
    "    vazio = ''\n",
    "    for palavra in e:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            vazio = vazio + \" \"+ palavra + \" \"\n",
    "        else:\n",
    "            vazio+= palavra\n",
    "    Lista_EMOJI.append(vazio)\n",
    "    \n",
    "TweetsStarbucks[\"Treinamento\"] = Lista_EMOJI\n",
    "\n",
    "\n",
    "#função para limpar os caracteres, os links e as risadasdos dos tweets :\n",
    "def limpeza(tweet):\n",
    "    \n",
    "    tweetlista = str(tweet)\n",
    "    tweetlista = tweetlista.replace(\",\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"#\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"@\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"!\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"$\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"%\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"&\",\"\")\n",
    "    tweetlista = tweetlista.replace(\".\",\"\")\n",
    "    tweetlista = tweetlista.replace(\";\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"¨\",\"\")\n",
    "    tweetlista = tweetlista.replace(\":\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"_\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"-\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"rt\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"?\",\"\")\n",
    "    tweetlista = tweetlista.replace(\">\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"<\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"»\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"…\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"1\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"2\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"3\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"4\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"5\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"6\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"7\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"8\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"9\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"(\",\"\")\n",
    "    tweetlista = tweetlista.replace(\")\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"[\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"]\",\"\")\n",
    "    tweetlista = tweetlista.replace(\"+\",\"\")\n",
    "    \n",
    "        \n",
    "    tweetlimpo = tweetlista\n",
    "    tweetlimpo = tweetlimpo.split()\n",
    "    \n",
    "    for palavra in tweetlimpo:\n",
    "        if 'https' in palavra:\n",
    "            tweetlimpo.remove(palavra)\n",
    "    for Palavra in tweetlimpo:\n",
    "        if 'kk' in Palavra:\n",
    "            tweetlimpo.remove(Palavra) \n",
    "    for Palavra in tweetlimpo:\n",
    "        if 'hah' in Palavra:\n",
    "            tweetlimpo.remove(Palavra)\n",
    "    for Palavra in tweetlimpo:\n",
    "        if 'rsr' in Palavra:\n",
    "            tweetlimpo.remove(Palavra)\n",
    " \n",
    "    return tweetlimpo  \n",
    "\n",
    "\n",
    "\n",
    "# CRIANDO UMA LISTA COM VÁRIAS LISTAS ONDE CADA UMA TEM UM TWEET\n",
    "tweetslimpolista = []\n",
    "for e in TweetsStarbucks.Treinamento:\n",
    "    tweetslimpos= limpeza(e)\n",
    "    tweetslimpolista.append(tweetslimpos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5491"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos juntar as palavras dos tweets relevantes e muito relevantes em um dicionario para facilitar na contagem e separação\n",
    "\n",
    "\n",
    "dictrel = {}\n",
    "\n",
    "for e in TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 3]:\n",
    "        tweetslimpos = limpeza(e)\n",
    "        for i in tweetslimpos:\n",
    "            if i in dictrel:\n",
    "                dictrel[i]+=1\n",
    "            else:\n",
    "                dictrel[i]=1\n",
    "\n",
    "\n",
    "for e in TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 4]:\n",
    "        tweetslimpos = limpeza(e)\n",
    "        for i in tweetslimpos:\n",
    "            \n",
    "            if i in dictrel:\n",
    "                dictrel[i]+=1\n",
    "            else:\n",
    "                dictrel[i]=1\n",
    "\n",
    "#contador de palavras relevantes\n",
    "soma_relevante =  0\n",
    "for palavra in dictrel:\n",
    "    soma_relevante += dictrel[palavra]\n",
    "    \n",
    "\n",
    "soma_relevante                \n",
    "\n",
    "\n",
    "#Vamos juntar as palavras dos tweets irrelevantes e muito irrelevantes em um dicionario para facilitar na contagem e separação\n",
    "\n",
    "dictirrel = {}\n",
    "\n",
    "for e in TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 1]:\n",
    "        tweetslimpos = limpeza(e)\n",
    "        for i in tweetslimpos:\n",
    "            if i in dictirrel:\n",
    "                dictirrel[i]+=1\n",
    "            else:\n",
    "                dictirrel[i]=1\n",
    "\n",
    "\n",
    "\n",
    "for e in TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 2]:\n",
    "        tweetslimpos = limpeza(e)\n",
    "        for i in tweetslimpos:\n",
    "            \n",
    "            if i in dictirrel:\n",
    "                dictirrel[i]+=1\n",
    "            else:\n",
    "                dictirrel[i]=1\n",
    "\n",
    "\n",
    "\n",
    "#contador de palavras irrelevantes\n",
    "soma_irrelevante =  0\n",
    "for palavra in dictirrel:\n",
    "    soma_irrelevante += dictirrel[palavra]\n",
    "    \n",
    "    \n",
    "    \n",
    "#total de palavras:\n",
    "total_de_palavras = soma_relevante + soma_irrelevante\n",
    "total_de_palavras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "#CALCULANDO A PROBABILIDADE DE SER IRRELEVANTE E RELEVANTE DADO OS TWEETS\n",
    "\n",
    "Numero_tweets1=TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 1]\n",
    "Numero_tweets2=TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 2]\n",
    "p_irrel=(len(Numero_tweets1)+len(Numero_tweets2))/300\n",
    "Numero_tweets3=TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 3]\n",
    "Numero_tweets4=TweetsStarbucks.Treinamento[TweetsStarbucks.Classificação == 4]\n",
    "p_rel=(len(Numero_tweets3)+len(Numero_tweets4))/300\n",
    "\n",
    "print(p_irrel)    # probabilidade de ser irrelevante\n",
    "print(p_rel)      # probabilidade de ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para calcular a probabilidade de ser relevante ou irrelevante\n",
    "\n",
    "def probabilidade(lista_de_tweets):\n",
    "    \n",
    "    prob_relevante = p_rel\n",
    "    prob_irrelevante = p_irrel\n",
    "    lista_classificacao = []\n",
    "    lista_classificacao_irr = []\n",
    "    \n",
    "    for tweet in lista_de_tweets:\n",
    "        \n",
    "        for palavra in tweet:\n",
    "            \n",
    "            pir_total = p_irrel\n",
    "            pr_total = p_rel\n",
    "            \n",
    "            if palavra not in dictrel:\n",
    "                x = 1/(soma_relevante+total_de_palavras)\n",
    "                pr_total += math.log(x)\n",
    "                \n",
    "            if palavra in dictrel:\n",
    "                x = dictrel[palavra]/(soma_relevante+total_de_palavras)\n",
    "                pr_total += math.log(x)\n",
    "\n",
    "            if palavra not in dictirrel:\n",
    "                x = 1/(soma_irrelevante+total_de_palavras)\n",
    "                pir_total += math.log(x)\n",
    "                \n",
    "            if palavra in dictirrel:\n",
    "                x = dictirrel[palavra]/(soma_irrelevante+total_de_palavras)\n",
    "                pir_total += math.log(x)\n",
    "                \n",
    "        if pr_total > pir_total:\n",
    "             lista_classificacao.append(tweet)\n",
    "                \n",
    "        elif pr_total < pir_total:\n",
    "             lista_classificacao_irr.append(tweet)\n",
    "                \n",
    "    return (\"P(relevante) = {0}  P(irrelevante) = {1}\".format((len(lista_classificacao))/(len(lista_de_tweets)),(len(lista_classificacao_irr))/(len(lista_de_tweets))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(relevante) = 0.935  P(irrelevante) = 0.065\n",
      "Probabilidade de ser irrelevante: 26.50%\n",
      "Probabilidade de ser relevante: 73.50%\n",
      "Probabilidade de ser muito irrelevante: 9.00%\n",
      "Probabilidade de ser pouco irrelevante: 17.50%\n",
      "Probabilidade de ser pouco relevante: 65.00%\n",
      "Probabilidade de ser muito relevante: 8.50%\n"
     ]
    }
   ],
   "source": [
    "TweetsStarbucksteste = pd.read_excel(\"Tweets_Starbucks.xlsx\",sheet_name = 1)\n",
    "\n",
    "#limpeza da parte de teste:\n",
    "\n",
    "Lista_EMOJI = []\n",
    "for e in TweetsStarbucksteste[\"Teste\"]:\n",
    "    vazio = ''\n",
    "    for palavra in e:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            vazio = vazio + \" \"+ palavra + \" \"\n",
    "        else:\n",
    "            vazio+= palavra\n",
    "    Lista_EMOJI.append(vazio)\n",
    "    \n",
    "TweetsStarbucksteste[\"Teste\"] = Lista_EMOJI\n",
    "\n",
    "#aplicando o código de calculo da probabilidade criado no treinamento\n",
    "lista_teste = []\n",
    "for frase in TweetsStarbucksteste.Teste:\n",
    "    tweetslimposteste = limpeza(frase)\n",
    "    lista_teste.append(tweetslimposteste)\n",
    "print(probabilidade(lista_teste))\n",
    "\n",
    "# Com o código limpo podemos rodar para calcular a probabilidade de cada modo de classificação\n",
    "\n",
    "contador0 = TweetsStarbucksteste.Classificação[TweetsStarbucksteste.Classificação == 1].count()\n",
    "contador1 = TweetsStarbucksteste.Classificação[TweetsStarbucksteste.Classificação == 2].count()\n",
    "contador2 = TweetsStarbucksteste.Classificação[TweetsStarbucksteste.Classificação == 3].count()\n",
    "contador3 = TweetsStarbucksteste.Classificação[TweetsStarbucksteste.Classificação == 4].count()\n",
    "\n",
    "contadorTotal = TweetsStarbucksteste.Classificação.count()\n",
    "contador01 = contador0+contador1\n",
    "\n",
    "\n",
    "P_01 = (contador0+contador1)/contadorTotal \n",
    "P_02 = (contador2+contador3)/contadorTotal \n",
    "P_0 = contador0/contadorTotal\n",
    "P_1 = contador1/contadorTotal \n",
    "P_2 = contador2/contadorTotal\n",
    "P_3 = contador3/contadorTotal\n",
    "P_4 = P_01\n",
    "P_5 = P_02\n",
    "\n",
    "print(\"Probabilidade de ser irrelevante: {:.2f}%\".format(P_4*100))\n",
    "print(\"Probabilidade de ser relevante: {:.2f}%\".format(P_5*100))\n",
    "print(\"Probabilidade de ser muito irrelevante: {:.2f}%\".format(P_0*100))\n",
    "print(\"Probabilidade de ser pouco irrelevante: {:.2f}%\".format(P_1*100))\n",
    "print(\"Probabilidade de ser pouco relevante: {:.2f}%\".format(P_2*100))\n",
    "print(\"Probabilidade de ser muito relevante: {:.2f}%\".format(P_3*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   A partir do classificador de Naive Bayes, é possível concluir que o método utilizado é uma ferramenta extremamente útil para a segregação e agrupamento de termos semelhantes/não semelhantes. A precisão de **78%** agrada bastante os engenheiros e(ou) desenvolvedores deste classificador, já que a separação dos tweets, neste caso especifico (em seguida falaremos de outras possíveis aplicações) é feita por relevância que é comprovadamente eficaz. Dentre as inúmeras possíveis aplicações para o classificador, podem ser citadas: um filtro de spam para e-mails; ferramenta de auxílio a diagnósticos médicos; categorizar notícias de jornais e com potencial para ser utilizado em programas de reconhecimento facial!\n",
    "Nós, desenvolvedores deste classificador, imaginamos que: analisar a enorme base de dados disponíveis, é o ponto de partida para as companhias modernas consigam elevar sua posição em relação a sua concorrência. Nosso programa através de Machine Learning relaciona as opiniões das pessoas sobre determinado assunto ou produto e a relevância que o mesmo possui sob o olhar do consumidor.\n",
    "\n",
    "## Proxima implementação\n",
    "\n",
    "Uma sugestão para uma futura implementação: reside no fato de que a inteligência artificial tem dificuldade em detectar gírias, ironias e sarcasmos por exemplo. Uma alternativa para tentar solucionar essas barreiras é uma maior coleta e analise de dados com a integração da biblioteca “scikit-learn”.\n",
    "\n",
    "*matrial de suporte:*\n",
    "http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
